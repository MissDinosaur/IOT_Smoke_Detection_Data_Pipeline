# ğŸ”¥ IoT Smoke Detection Data Pipeline

A **production-ready, enterprise-grade** real-time data pipeline for IoT smoke detection using Apache Kafka, Apache Spark, Machine Learning, and comprehensive automation.

## ğŸ—ï¸ **Complete Architecture Overview**

This project implements a **comprehensive end-to-end ML-powered data pipeline** for processing IoT sensor data to detect smoke and fire incidents in real-time with full automation and monitoring.

### **ğŸ¯ Key Capabilities**
- âš¡ **Real-time Stream Processing** with sub-second latency
- ğŸ¤– **Automated ML Pipeline** with training, deployment, and monitoring
- ğŸ“Š **Comprehensive Data Quality** monitoring and validation
- ğŸ”„ **Self-Healing Architecture** with automatic recovery
- ğŸ“ˆ **Enterprise Monitoring** with alerts and reporting
- ğŸš€ **One-Command Deployment** with Docker Compose

## ğŸš€ **Quick Start**

### **Prerequisites**
- Docker Desktop (latest version)
- 8GB+ RAM (16GB recommended)
- 10GB+ free disk space

### **ğŸ¬ One-Command Setup**
```bash
# Clone and start the complete pipeline
git clone <repository-url>
cd IOT_Smoke_Detection_Data_Pipeline

# Start everything with one command
docker-compose up --build

# Verify deployment
scripts/verify_end_to_end.bat  # Windows
./scripts/verify_end_to_end.sh # Linux/Mac
```

### **ğŸŒ Access Points**
- **Spark UI**: http://localhost:4040 (Real-time stream monitoring)
- **ML API**: http://localhost:5000 (Machine learning service)
- **Airflow UI**: http://localhost:8080 (Workflow management, admin/admin)

## ğŸ›ï¸ **Microservices Architecture**

### **ğŸ”„ Core Services**
| Service | Purpose | Port | Health Check |
|---------|---------|------|--------------|
| **kafka** | Message broker | 9092 | Kafka topics |
| **kafka_producer** | Data ingestion | - | Message production |
| **stream_processor** | Basic analytics | - | Processing logs |
| **spark_stream_processor** | ML-enhanced analytics | 4040 | Spark UI |
| **ml_trainer** | Automatic model training | - | Model files |
| **ml_api** | ML prediction service | 5000 | `/health` endpoint |
| **airflow** | Workflow orchestration | 8080 | Airflow UI |
| **postgres** | Metadata storage | 5432 | Database connection |

### **ğŸ“¦ Container Dependencies**
```
postgres â†’ airflow
zookeeper â†’ kafka â†’ kafka_producer
kafka â†’ stream_processor
kafka â†’ spark_stream_processor
ml_trainer â†’ ml_api â†’ spark_stream_processor
```

## ğŸ¤– **Complete ML Pipeline**

### **ğŸ”„ Automated ML Lifecycle**
```
Data Collection â†’ Quality Validation â†’ Feature Engineering â†’ Model Training â†’ 
Validation â†’ Deployment â†’ Monitoring â†’ Retraining â†’ Performance Analysis
```

### **ğŸ¯ ML Components**
- **Training Service**: Automatic model training with validation
- **Prediction API**: Real-time ML inference service
- **Performance Monitoring**: Continuous model health tracking
- **Drift Detection**: Automatic model degradation detection
- **Model Management**: Versioning, deployment, and rollback

## ğŸ“… **Automated Operations Schedule**

| Time | Operation | Frequency | Purpose |
|------|-----------|-----------|---------|
| **02:00** | ML Training | Daily | Model training & deployment |
| **06:00** | Batch Processing | Daily | Feature engineering & metrics |
| **Every 6h** | Data Quality Check | 4x Daily | Quality monitoring & alerts |
| **Every 12h** | Performance Monitor | 2x Daily | Model performance tracking |
| **Sun 03:00** | Historical Analysis | Weekly | Pattern discovery & insights |

## ğŸ”§ **Configuration Management**

### **Environment Variables** (`.env`)
```bash
# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
KAFKA_TOPIC_SMOKE=smoke_sensor_data

# ML Configuration
ML_AUTO_TRAIN_ON_STARTUP=true
ML_TRAINING_INTERVAL_HOURS=24
ML_API_URL=http://ml_api:5000

# Database Configuration
POSTGRES_DB=airflow
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow

# Airflow Configuration
AIRFLOW_UID=50000
AIRFLOW__CORE__EXECUTOR=LocalExecutor
```

## ğŸ“ **Project Structure**

```
ğŸ“¦ IOT_Smoke_Detection_Data_Pipeline/
â”œâ”€â”€ ğŸ“‚ data_ingestion/              # Data ingestion layer
â”‚   â”œâ”€â”€ ğŸ“‚ stream/                  # Kafka producers
â”‚   â””â”€â”€ ğŸ“‚ batch/                   # Batch data loaders
â”œâ”€â”€ ğŸ“‚ data_processing/             # Processing layer
â”‚   â”œâ”€â”€ ğŸ“‚ stream_processing/       # Real-time processing
â”‚   â”‚   â”œâ”€â”€ spark_streaming_processor.py
â”‚   â”‚   â”œâ”€â”€ historical_ml_processor.py
â”‚   â”‚   â””â”€â”€ README_SPARK.md
â”‚   â””â”€â”€ ğŸ“‚ batch_processing/        # Batch processing
â”‚       â”œâ”€â”€ ğŸ“‚ dags/               # Airflow DAGs
â”‚       â”œâ”€â”€ ğŸ“‚ tasks/              # Processing tasks
â”‚       â””â”€â”€ README_DAGS.md
â”œâ”€â”€ ğŸ“‚ ml/                         # Machine learning layer
â”‚   â”œâ”€â”€ ğŸ“‚ training/               # Model training
â”‚   â”‚   â”œâ”€â”€ train_model.py
â”‚   â”‚   â”œâ”€â”€ auto_trainer.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ ğŸ“‚ inference/              # Model inference
â”‚   â”‚   â”œâ”€â”€ predict_wrapper.py
â”‚   â”‚   â”œâ”€â”€ model_loader.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ ğŸ“‚ models/                 # Trained models
â”œâ”€â”€ ğŸ“‚ config/                     # Configuration files
â”œâ”€â”€ ğŸ“‚ data/                       # Data storage
â”œâ”€â”€ ğŸ“‚ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ verify_end_to_end.sh
â”‚   â””â”€â”€ verify_end_to_end.bat
â”œâ”€â”€ ğŸ“„ docker-compose.yml          # Service orchestration
â”œâ”€â”€ ğŸ“„ Dockerfile.spark            # Spark container
â”œâ”€â”€ ğŸ“„ Dockerfile.ml               # ML services container
â”œâ”€â”€ ğŸ“„ requirements.txt            # Python dependencies
â”œâ”€â”€ ğŸ“„ STARTUP_GUIDE.md           # Deployment guide
â””â”€â”€ ğŸ“„ README.md                   # This file
```

## ğŸ”„ **Data Flow Architecture**

```
IoT Sensors â†’ CSV Data â†’ Kafka Producer â†’ Apache Kafka
                                              â†“
                                    Stream Processors
                                    â”œâ”€â”€ Regular Analytics
                                    â””â”€â”€ Spark + ML Analytics
                                              â†“
                                        ML Services
                                    â”œâ”€â”€ Auto Training
                                    â””â”€â”€ Prediction API
                                              â†“
                                      Batch Processing
                                    â”œâ”€â”€ Quality Monitoring
                                    â”œâ”€â”€ Performance Tracking
                                    â”œâ”€â”€ Historical Analysis
                                    â””â”€â”€ Model Management
                                              â†“
                                    Storage & Monitoring
                                    â”œâ”€â”€ PostgreSQL
                                    â”œâ”€â”€ Data Files
                                    â””â”€â”€ Reports & Logs
```

## ğŸ¯ **Key Features**

### **âœ… Real-time Processing**
- Sub-second latency for critical alerts
- Windowed analytics (5-minute windows, 1-minute slides)
- 25+ statistical measures per window
- ML-enhanced fire detection

### **âœ… Automated ML Pipeline**
- Automatic model training on startup
- Daily retraining with validation
- Real-time predictions via API
- Performance monitoring and drift detection

### **âœ… Comprehensive Monitoring**
- Data quality validation every 6 hours
- Model performance tracking every 12 hours
- Historical analysis weekly
- Automated alert generation

### **âœ… Enterprise Features**
- Fault-tolerant architecture
- Automatic service recovery
- Comprehensive logging and reporting
- Scalable microservices design

## ğŸ“Š **Expected Output**

### **Real-time Analytics**
```
ğŸ“Š Window Analytics (2024-01-15 10:00:00 - 2024-01-15 10:05:00):
Records: 1,247, Temp: 26.8Â°C (Ïƒ=2.3), Humidity: 52.1%
TVOC: 185.4ppb (max=245.0), PM2.5: 12.3Î¼g/mÂ³
Fire Alarms: 0, Quality: 95.2%, ML: No Fire (0.85)
```

### **ML Training Results**
```
ğŸ¤– Starting automatic ML model training...
âœ… Model saved: best_model.pkl
ğŸ¯ Training Results:
   Best Model: RandomForestClassifier
   Accuracy: 0.945
   Precision: 0.892
   Recall: 0.876
   F1-Score: 0.884
```

### **Service Health**
```
CONTAINER NAME           STATUS              PORTS
ml_trainer              Up 2 minutes        (Training Service)
ml_api                  Up 2 minutes        5000/tcp
spark_stream_processor  Up 1 minute         4040/tcp
airflow                 Up 1 minute         8080/tcp
```

## ğŸ” **Monitoring & Alerting**

### **Data Quality Alerts**
- Critical: Overall quality score < 70%
- Warning: Anomaly rate > 10%
- Info: Completeness < 90% for any sensor

### **Model Performance Alerts**
- Critical: Model accuracy < 70%
- Warning: Response time > 5 seconds
- Info: Drift indicators detected

### **System Health Alerts**
- Critical: ML API not responding
- Warning: Training failures
- Info: Storage cleanup needed

## ğŸ“š **Documentation**

- [ğŸš€ Startup Guide](STARTUP_GUIDE.md) - Complete deployment instructions
- [âš¡ Stream Processing](data_processing/stream_processing/README_SPARK.md) - Real-time analytics
- [ğŸ”„ Batch Processing](data_processing/batch_processing/README_DAGS.md) - Airflow DAGs
- [ğŸ¤– ML Training](ml/training/README.md) - Model training guide
- [ğŸ”® ML API](ml/inference/README.md) - Prediction API documentation

## ğŸ‰ **Benefits**

### **âœ… Complete Automation**
- Zero manual intervention required
- Automatic model training and deployment
- Self-healing architecture
- Comprehensive monitoring

### **âœ… Production Ready**
- Enterprise-grade reliability
- Scalable microservices architecture
- Comprehensive error handling
- Full observability

### **âœ… ML-Powered**
- Real-time ML predictions
- Automatic model retraining
- Performance monitoring
- Drift detection

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ **License**

This project is licensed under the MIT License - see the LICENSE file for details.

---

**ğŸš€ Ready to deploy? Run `docker-compose up --build` and experience the complete IoT smoke detection pipeline!**
