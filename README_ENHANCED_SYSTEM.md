# ðŸ”¥ IoT Smoke Detection Data Pipeline - Enhanced ML System

## ðŸš€ **New Features Implemented**

### **1. âœ… ML Training Completion Before Container Startup**
- **ML Trainer** runs first and completes initial model training
- **Flask API** waits for ML trainer to be healthy before starting
- **Spark Processor** waits for Flask API to be ready
- **Health checks** ensure proper startup sequence

### **2. âœ… Local Model Persistence**
- Models saved to `./models/` directory on host system
- **Persistent across container restarts**
- **Accessible for backup and version control**
- **Shared between containers via volume mounts**

### **3. âœ… Daily Model Retraining**
- **Automatic retraining** at 2 AM daily (configurable)
- **New data integration** for continuous improvement
- **Model versioning** with timestamp backups
- **Seamless model updates** without service interruption

### **4. âœ… Dependency Management**
- **Health checks** for all critical services
- **Proper startup ordering** with `depends_on` conditions
- **Graceful failure handling** and retry mechanisms
- **Service readiness validation**

## ðŸ“ **Directory Structure**

```
IOT_Smoke_Detection_Data_Pipeline/
â”œâ”€â”€ models/                          # ðŸ†• Local models directory
â”‚   â”œâ”€â”€ smoke_detection_model.pkl    # Current production model
â”‚   â”œâ”€â”€ model_backup_*.pkl          # Timestamped backups
â”‚   â””â”€â”€ README.md                   # Model documentation
â”œâ”€â”€ ml/
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ train_model.py          # Enhanced training script
â”‚       â”œâ”€â”€ auto_trainer.py         # ðŸ†• Enhanced daily retraining
â”‚       â””â”€â”€ initial_model_generator.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ setup_models_directory.sh   # ðŸ†• Models directory setup
â”œâ”€â”€ start_system.sh                 # ðŸ†• Orchestrated startup script
â”œâ”€â”€ test_system.sh                  # ðŸ†• System testing script
â””â”€â”€ docker-compose.yml              # ðŸ†• Enhanced with dependencies
```

## ðŸš€ **Quick Start**

### **1. Setup and Start System**
```bash
# Make scripts executable
chmod +x start_system.sh test_system.sh scripts/setup_models_directory.sh

# Start the entire system (handles all dependencies)
./start_system.sh
```

### **2. Monitor Training Progress**
```bash
# Watch ML training logs (initial training takes 30-60 minutes)
docker-compose logs -f ml_trainer

# Check Flask API logs
docker-compose logs -f flask_api
```

### **3. Test System**
```bash
# Run system tests
./test_system.sh

# Run comprehensive test suite
python tests/run_streaming_tests.py --all --html-report
```

## ðŸ”„ **Startup Sequence**

### **Phase 1: Infrastructure (0-30 seconds)**
1. **Kafka & Zookeeper** - Message streaming infrastructure
2. **PostgreSQL** - Database for Airflow

### **Phase 2: ML Training (30-60 minutes)**
3. **ML Trainer** - Trains initial model with your perfect 100% accuracy
4. **Model Saving** - Saves to both local and shared locations

### **Phase 3: API Services (1-2 minutes)**
5. **Flask API** - Waits for model, then starts API server
6. **Health Checks** - Validates API is ready

### **Phase 4: Processing Services (1-2 minutes)**
7. **Spark Processor** - Waits for Flask API, then starts streaming
8. **Other Services** - Airflow, monitoring, etc.

## ðŸ¤– **ML Model Management**

### **Training Schedule**
- **Initial Training**: On first startup (30-60 minutes)
- **Daily Retraining**: Every day at 2 AM (configurable)
- **Manual Retraining**: `docker-compose restart ml_trainer`

### **Model Locations**
```bash
# Local host directory (persistent)
./models/smoke_detection_model.pkl

# Inside ML container
/app/ml/models/best_model.pkl

# Shared container location
/app/models/smoke_detection_model.pkl
```

### **Model Backup Strategy**
- **Timestamped backups**: `model_backup_YYYYMMDD_HHMMSS.pkl`
- **Keep last 5 models** in container
- **Local persistence** for long-term storage
- **Automatic cleanup** of old models

## ðŸ“Š **Service Dependencies**

```mermaid
graph TD
    A[Kafka/Zookeeper] --> B[ML Trainer]
    B --> C[Flask API]
    C --> D[Spark Processor]
    B --> E[Model Files]
    E --> C
    C --> F[Monitoring]
```

## ðŸ”§ **Configuration**

### **Environment Variables**
```bash
# ML Training Configuration
ML_TRAINING_INTERVAL_HOURS=24    # Retraining interval
ML_RETRAIN_HOUR=02               # Daily retraining time (2 AM)
MODEL_SAVE_LOCAL=true            # Save to local directory
MODEL_SAVE_SHARED=true           # Save to shared location

# Flask API Configuration
MODEL_PATH=/app/models/smoke_detection_model.pkl
MODEL_RELOAD_INTERVAL=3600       # Check for updates every hour
```

### **Health Check Configuration**
```yaml
ml_trainer:
  healthcheck:
    test: ["CMD", "test", "-f", "/app/models/smoke_detection_model.pkl"]
    interval: 30s
    timeout: 10s
    retries: 10
    start_period: 3600s  # Wait 60 minutes for initial training

flask_api:
  depends_on:
    ml_trainer:
      condition: service_healthy
```

## ðŸŽ¯ **Expected Performance**

### **With Your Perfect ML Model (100% Accuracy)**
- **Training Time**: 30-60 minutes for initial model
- **API Response Time**: < 50ms per prediction
- **Model Accuracy**: 100% (as achieved in your training)
- **Daily Retraining**: Automatic at 2 AM
- **Zero Downtime**: Model updates without service interruption

### **System Startup Times**
- **Infrastructure**: 30 seconds
- **ML Training**: 30-60 minutes (first time only)
- **API Services**: 1-2 minutes
- **Total System Ready**: ~60 minutes (first startup), ~5 minutes (subsequent)

## ðŸ§ª **Testing**

### **System Tests**
```bash
# Quick system test
./test_system.sh

# Comprehensive test suite
python tests/run_streaming_tests.py --all

# ML-specific tests
python tests/run_streaming_tests.py --ml --flask

# Performance tests
python tests/run_streaming_tests.py --ml-performance
```

### **Manual Testing**
```bash
# Test API health
curl http://localhost:5000/health

# Test model info
curl http://localhost:5000/model/info

# Test prediction
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"Temperature[C]": 25.5, "Humidity[%]": 45.0, ...}'
```

## ðŸ›  **Troubleshooting**

### **Common Issues**

#### **Model Training Takes Too Long**
```bash
# Check training progress
docker-compose logs -f ml_trainer

# Check data availability
docker-compose exec ml_trainer ls -la /app/data/
```

#### **Flask API Can't Load Model**
```bash
# Check model file exists
ls -la ./models/
docker-compose exec flask_api ls -la /app/models/

# Check Flask API logs
docker-compose logs flask_api
```

#### **Services Won't Start**
```bash
# Check service dependencies
docker-compose ps

# Restart specific service
docker-compose restart <service_name>

# Full system restart
docker-compose down && ./start_system.sh
```

## ðŸŽ‰ **Benefits of Enhanced System**

1. **ðŸ”’ Reliable Startup** - No more "model not found" errors
2. **ðŸ’¾ Persistent Models** - Models survive container restarts
3. **ðŸ”„ Automatic Updates** - Daily retraining with new data
4. **ðŸ“Š Perfect Accuracy** - Your 100% accurate model in production
5. **ðŸ§ª Comprehensive Testing** - Full test coverage for ML pipeline
6. **ðŸ“ˆ Production Ready** - Robust dependency management

Your IoT Smoke Detection system is now production-ready with automatic ML model management! ðŸš€
